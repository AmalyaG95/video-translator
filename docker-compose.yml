version: "3.8"

services:
  # Frontend - Next.js
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://localhost:3001}
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=${NEXT_PUBLIC_API_URL:-http://localhost:3001}
      - NODE_ENV=${NODE_ENV:-production}
      - WATCHPACK_POLLING=true
    volumes:
      # Mount source code for hot reload (exclude node_modules and .next)
      - ./frontend:/app
      - /app/node_modules
      - /app/.next
    depends_on:
      - nestjs-api
    networks:
      - translator-network
    restart: unless-stopped
    command: >
      sh -c "
        if [ \"$$NODE_ENV\" = \"development\" ]; then
          npm run dev
        else
          npm start
        fi
      "

  # NestJS API Gateway
  nestjs-api:
    build:
      context: ./backend-nestjs
      dockerfile: Dockerfile
    ports:
      - "3001:3001"
    environment:
      - PORT=3001
      - FRONTEND_URL=http://frontend:3000
      - GRPC_ML_SERVICE_URL=python-ml-v2:50051
      - NODE_ENV=${NODE_ENV:-production}
      - WATCHPACK_POLLING=true
    volumes:
      - ./uploads:/app/uploads
      - ./artifacts:/app/artifacts
      # Mount source code for hot reload in development
      - ./backend-nestjs/src:/app/src
      - ./backend-nestjs/package.json:/app/package.json
      - ./backend-nestjs/package-lock.json:/app/package-lock.json
      - ./backend-nestjs/tsconfig.json:/app/tsconfig.json
      - ./backend-nestjs/tsconfig.build.json:/app/tsconfig.build.json
      - ./backend-nestjs/nest-cli.json:/app/nest-cli.json
      - /app/node_modules
      # Don't mount /app/dist - it's built into the image for production
      # and should be created inside container for development to avoid EBUSY errors
    # depends_on removed - python-ml-v2 is in docker-compose.v2.yml
    # Services communicate via shared translator-network
    networks:
      - translator-network
    restart: unless-stopped
    command: >
      sh -c "
        if [ \"$$NODE_ENV\" = \"development\" ]; then
          npm install && npm run start:dev
        else
          node dist/main
        fi
      "

  # Python ML Microservice
  python-ml:
    build:
      context: ./backend-python-ml
      dockerfile: Dockerfile
    ports:
      - "50051:50051"
    volumes:
      - ./uploads:/app/uploads
      - ./artifacts:/app/artifacts
      # Mount all source code to avoid rebuilds on code changes
      - ./backend-python-ml/src:/app/src
      - ./backend-python-ml/src/config:/app/src/config
      # Mount entrypoint and requirements so changes are visible
      - ./backend-python-ml/entrypoint.sh:/app/entrypoint.sh
      - ./backend-python-ml/requirements.txt:/app/requirements.txt
      - temp-work:/app/temp_work
    environment:
      - PYTHONUNBUFFERED=1
      - PYTHONDONTWRITEBYTECODE=1
    deploy:
      resources:
        limits:
          memory: 8G
          cpus: "4"
        reservations:
          memory: 4G
          cpus: "2"
    networks:
      - translator-network
    restart: unless-stopped
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import grpc; grpc.insecure_channel('localhost:50051')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  translator-network:
    external: true

volumes:
  temp-work:
    driver: local
