"""
gRPC Translation Service Implementation
Handles translation requests and streams progress back to NestJS API
"""

import asyncio
import logging
from typing import Iterator, Dict, Any
from pathlib import Path
import json

import grpc
import translation_pb2, translation_pb2_grpc
from pipeline.compliant_pipeline import CompliantVideoTranslationPipeline
from utils.path_resolver import path_resolver, get_session_artifacts

logger = logging.getLogger(__name__)


class TranslationServicer(translation_pb2_grpc.TranslationServiceServicer):
    """gRPC servicer for video translation"""
    
    def __init__(self):
        self.pipeline = CompliantVideoTranslationPipeline()
        self.active_sessions: Dict[str, Any] = {}
        self.cancellation_events: Dict[str, asyncio.Event] = {}
        logger.info("Translation servicer initialized")
        
        # Log environment information
        env_info = path_resolver.get_environment_info()
        logger.info(f"Environment: {'Docker' if env_info['is_docker'] else 'Local Development'}")
        logger.info(f"Artifacts directory: {env_info['base_paths']['artifacts']}")
        logger.info(f"Temp work directory: {env_info['base_paths']['temp_work']}")
    
    async def TranslateVideo(
        self,
        request: translation_pb2.TranslationRequest,
        context: grpc.aio.ServicerContext
    ) -> Iterator[translation_pb2.TranslationProgress]:
        """Stream translation progress"""
        session_id = request.session_id
        logger.info(f"Starting translation for session: {session_id}")
        
        # Create cancellation event and progress queue
        cancellation_event = asyncio.Event()
        self.cancellation_events[session_id] = cancellation_event
        progress_queue = asyncio.Queue()
        
        # Sentinel value to signal completion
        DONE = object()
        
        async def run_pipeline():
            """Run pipeline in background task"""
            try:
                logger.info(f"Starting pipeline for session {session_id}")
                logger.info(f"File: {request.file_path}, {request.source_lang} -> {request.target_lang}")
                
                # Progress callback that puts updates in queue
                async def progress_callback(progress: int, message: str, **kwargs):
                    """Put progress updates in queue"""
                    try:
                        await progress_queue.put({
                            'progress': progress,
                            'current_step': message,
                            'status': kwargs.get('status', 'processing'),
                            'message': kwargs.get('message', ''),
                            'early_preview_available': kwargs.get('early_preview_available', False),
                            'early_preview_path': kwargs.get('early_preview_path', ''),
                            'current_chunk': kwargs.get('current_chunk', 0),
                            'total_chunks': kwargs.get('total_chunks', 0)
                        })
                    except Exception as e:
                        logger.error(f"Error in progress callback: {e}")
                
                # Generate output path using dynamic path resolver
                session_artifacts = get_session_artifacts(session_id)
                output_path = session_artifacts['translated_video']
                
                # Run pipeline with callback
                result = await self.pipeline.process_video(
                    video_path=Path(request.file_path),
                    source_lang=request.source_lang,
                    target_lang=request.target_lang,
                    output_path=output_path,
                    session_id=session_id,
                    progress_callback=progress_callback
                )
                
                logger.info(f"Pipeline result: success={result.get('success')}, error={result.get('error')}")
                if not result.get('success'):
                    logger.error(f"Pipeline failed: {result.get('error')}")
                    await progress_queue.put({'error': str(result.get('error', 'Unknown error'))})
                
                # Store result with AI insights
                result['ai_insights'] = self.pipeline.get_ai_insights()
                self.active_sessions[session_id] = result
                
                # Signal completion
                await progress_queue.put(DONE)
                
                logger.info(f"Translation completed for session: {session_id}")
                return result
                
            except Exception as e:
                logger.error(f"Pipeline error: {e}", exc_info=True)
                await progress_queue.put({'error': str(e)})
                await progress_queue.put(DONE)
                return {'success': False, 'error': str(e)}


        # Start pipeline in background
        pipeline_task = asyncio.create_task(run_pipeline())
        
        try:
            # Initial progress
            yield translation_pb2.TranslationProgress(
                session_id=session_id,
                progress=0,
                current_step='Starting translation',
                status='processing',
                message='Initializing pipeline'
            )
            
            # Stream progress updates from queue
            while True:
                try:
                    # Check if context is cancelled
                    if context.cancelled():
                        logger.warning(f"Context cancelled for session: {session_id}")
                        cancellation_event.set()
                        pipeline_task.cancel()
                        break
                    
                    # Get progress update with timeout
                    update = await asyncio.wait_for(progress_queue.get(), timeout=1.0)
                    
                    # Check for completion
                    if update is DONE:
                        break
                    
                    # Check for error
                    if 'error' in update:
                        yield translation_pb2.TranslationProgress(
                            session_id=session_id,
                            status='failed',
                            message=f"Translation failed: {update['error']}"
                        )
                        break
                    
                    # Calculate enhanced progress fields
                    current_progress = update.get('progress', 0)
                    eta_seconds = self.calculate_eta(session_id, current_progress)
                    hardware_info = self.get_hardware_info()
                    available_segments = update.get('available_segments', [])
                    chunks_per_minute = update.get('chunks_per_minute', 0)
                    current_chunk = update.get('current_chunk', 0)
                    total_chunks = update.get('total_chunks', 0)
                    
                    print(f"DEBUG: Sending progress update - current_chunk: {current_chunk}, total_chunks: {total_chunks}")
                    print(f"DEBUG: Full update data: {update}")
                    
                    # Send enhanced progress update
                    yield translation_pb2.TranslationProgress(
                        session_id=session_id,
                        progress=current_progress,
                        current_step=update.get('current_step', ''),
                        status=update.get('status', 'processing'),
                        message=update.get('message', ''),
                        early_preview_available=update.get('early_preview_available', False),
                        early_preview_path=update.get('early_preview_path', ''),
                        # Enhanced fields
                        eta_seconds=eta_seconds,
                        hardware_info=translation_pb2.HardwareInfo(
                            cpu=hardware_info['cpu'],
                            gpu=hardware_info['gpu'],
                            vram_gb=hardware_info['vram_gb'],
                            ram_gb=hardware_info['ram_gb']
                        ),
                        available_segment_ids=available_segments,
                        chunks_per_minute=chunks_per_minute,
                        current_chunk=current_chunk,
                        total_chunks=total_chunks
                    )
                    
                except asyncio.TimeoutError:
                    # Just continue waiting
                    continue
            
            # Send final completion only if no error occurred
            # Check if pipeline task completed successfully
            if pipeline_task.done() and not pipeline_task.cancelled():
                try:
                    pipeline_result = pipeline_task.result()
                    if pipeline_result and pipeline_result.get('success', False):
                        yield translation_pb2.TranslationProgress(
                            session_id=session_id,
                            progress=100,
                            current_step='Completed',
                            status='completed',
                            message='Translation completed successfully'
                        )
                    else:
                        yield translation_pb2.TranslationProgress(
                            session_id=session_id,
                            status='failed',
                            message='Translation failed during processing'
                        )
                except Exception as e:
                    yield translation_pb2.TranslationProgress(
                        session_id=session_id,
                        status='failed',
                        message=f'Translation failed: {str(e)}'
                    )
            else:
                yield translation_pb2.TranslationProgress(
                    session_id=session_id,
                    status='failed',
                    message='Translation was cancelled or failed'
                )
            
        except asyncio.CancelledError:
            logger.warning(f"Translation cancelled for session: {session_id}")
            pipeline_task.cancel()
            yield translation_pb2.TranslationProgress(
                session_id=session_id,
                status='failed',
                message='Translation cancelled'
            )
            
        except Exception as e:
            logger.error(f"Streaming error for session {session_id}: {e}", exc_info=True)
            pipeline_task.cancel()
            yield translation_pb2.TranslationProgress(
                session_id=session_id,
                status='failed',
                message=f'Translation failed: {str(e)}'
            )
        
        finally:
            # Cleanup
            self.cancellation_events.pop(session_id, None)
            if not pipeline_task.done():
                pipeline_task.cancel()

    def get_ai_insights(self, session_id: str) -> Dict[str, Any]:
        """Get AI insights for a completed session"""
        session = self.active_sessions.get(session_id)
        if session and 'ai_insights' in session:
            return {
                'insights': session['ai_insights'],
                'total_insights': len(session['ai_insights']),
                'session_id': session_id
            }
        return {
            'insights': [],
            'total_insights': 0,
            'session_id': session_id,
            'error': 'Session not found or no insights available'
        }
    
    async def GetTranslationResult(
        self,
        request: translation_pb2.ResultRequest,
        context: grpc.aio.ServicerContext
    ) -> translation_pb2.TranslationResult:
        """Get translation result"""
        session_id = request.session_id
        logger.info(f"Getting result for session: {session_id}")
        
        result = self.active_sessions.get(session_id)
        
        if not result:
            context.abort(
                grpc.StatusCode.NOT_FOUND,
                f"No result found for session: {session_id}"
            )
        
        # Extract SRT files from nested dict
        srt_files = result.get('srt_files', {})
        
        # Extract quality metrics if available
        quality_metrics_dict = result.get('quality_metrics', {})
        quality_metrics = None
        if quality_metrics_dict:
            quality_metrics = translation_pb2.QualityMetrics(
                lip_sync_accuracy=quality_metrics_dict.get('lip_sync_accuracy', 85.0),
                voice_quality=quality_metrics_dict.get('voice_quality', 80.0),
                translation_quality=quality_metrics_dict.get('translation_quality', 90.0),
                duration_match=quality_metrics_dict.get('duration_match', True),
                avg_lufs=quality_metrics_dict.get('avg_lufs', -18.0),
                avg_atempo=quality_metrics_dict.get('avg_atempo', 1.0),
                segments_condensed=quality_metrics_dict.get('segments_condensed', 0)
            )
        
        return translation_pb2.TranslationResult(
            session_id=session_id,
            output_path=result.get('output_path', ''),
            status='completed' if result.get('success') else 'failed',
            duration=int(result.get('processing_time', 0)),
            original_srt=srt_files.get('original', ''),
            translated_srt=srt_files.get('translated', ''),
            quality_metrics=quality_metrics,
            output_size=result.get('output_size', 0),
            original_size=result.get('original_size', 0),
            processing_time_seconds=result.get('processing_time_seconds', 0.0)
        )
    
    async def DetectLanguage(
        self,
        request: translation_pb2.LanguageDetectionRequest,
        context: grpc.aio.ServicerContext
    ) -> translation_pb2.LanguageDetectionResult:
        """Detect language from video file"""
        file_path = request.file_path
        logger.info(f"Detecting language for file: {file_path}")
        
        try:
            # Use the pipeline to detect language
            detected_language, confidence = await self.pipeline.detect_language(file_path)
            
            return translation_pb2.LanguageDetectionResult(
                detected_language=detected_language,
                confidence=confidence,
                success=True,
                message=f"Language detected: {detected_language} (confidence: {confidence:.2f})"
            )
        except Exception as e:
            logger.error(f"Language detection failed: {str(e)}")
            return translation_pb2.LanguageDetectionResult(
                detected_language='en',  # Default to English
                confidence=0.5,
                success=False,
                message=f"Language detection failed: {str(e)}"
            )
    
    async def CancelTranslation(
        self,
        request: translation_pb2.CancelRequest,
        context: grpc.aio.ServicerContext
    ) -> translation_pb2.CancelResponse:
        """Cancel ongoing translation"""
        session_id = request.session_id
        logger.info(f"Cancelling translation for session: {session_id}")
        
        cancellation_event = self.cancellation_events.get(session_id)
        
        if cancellation_event:
            cancellation_event.set()
            return translation_pb2.CancelResponse(
                success=True,
                message=f"Translation cancelled for session: {session_id}"
            )
        else:
            return translation_pb2.CancelResponse(
                success=False,
                message=f"No active translation found for session: {session_id}"
            )

    async def ControlTranslation(
        self,
        request: translation_pb2.ControlTranslationRequest,
        context: grpc.aio.ServicerContext
    ) -> translation_pb2.ControlTranslationResponse:
        """Control translation (pause/resume/cancel)"""
        session_id = request.session_id
        action = request.action
        logger.info(f"Control translation request for session {session_id}: {action}")
        
        try:
            if action == "pause":
                # Set pause flag in active session
                if session_id in self.active_sessions:
                    self.active_sessions[session_id]['paused'] = True
                    logger.info(f"Translation paused for session: {session_id}")
                    return translation_pb2.ControlTranslationResponse(
                        success=True,
                        is_paused=True,
                        message=f"Translation paused for session: {session_id}"
                    )
                else:
                    return translation_pb2.ControlTranslationResponse(
                        success=False,
                        is_paused=False,
                        message=f"No active translation found for session: {session_id}"
                    )
            
            elif action == "resume":
                # Clear pause flag in active session
                if session_id in self.active_sessions:
                    self.active_sessions[session_id]['paused'] = False
                    logger.info(f"Translation resumed for session: {session_id}")
                    return translation_pb2.ControlTranslationResponse(
                        success=True,
                        is_paused=False,
                        message=f"Translation resumed for session: {session_id}"
                    )
                else:
                    return translation_pb2.ControlTranslationResponse(
                        success=False,
                        is_paused=False,
                        message=f"No active translation found for session: {session_id}"
                    )
            
            elif action == "cancel":
                # Cancel translation and export partials
                if session_id in self.cancellation_events:
                    self.cancellation_events[session_id].set()
                    logger.info(f"Translation cancellation requested for session: {session_id}")
                    
                    # Export partial video if possible
                    try:
                        partial_path = await self.export_partial_video(session_id)
                        message = f"Translation cancelled for session: {session_id}"
                        if partial_path:
                            message += f". Partial video exported to: {partial_path}"
                    except Exception as e:
                        logger.warning(f"Failed to export partial video: {e}")
                        message = f"Translation cancelled for session: {session_id}. Partial export failed: {e}"
                    
                    return translation_pb2.ControlTranslationResponse(
                        success=True,
                        is_paused=False,
                        message=message
                    )
                else:
                    return translation_pb2.ControlTranslationResponse(
                        success=False,
                        is_paused=False,
                        message=f"No active translation found for session: {session_id}"
                    )
            
            else:
                return translation_pb2.ControlTranslationResponse(
                    success=False,
                    is_paused=False,
                    message=f"Invalid action: {action}. Must be 'pause', 'resume', or 'cancel'"
                )
                
        except Exception as e:
            logger.error(f"Error controlling translation: {e}")
            return translation_pb2.ControlTranslationResponse(
                success=False,
                is_paused=False,
                message=f"Error controlling translation: {e}"
            )

    async def GetAIInsights(
        self,
        request: translation_pb2.AIInsightsRequest,
        context: grpc.aio.ServicerContext
    ) -> translation_pb2.AIInsightsResponse:
        """Get AI insights for a session"""
        session_id = request.session_id
        logger.info(f"Getting AI insights for session: {session_id}")
        
        try:
            insights_data = self.get_ai_insights(session_id)
            
            # Convert insights to protobuf format
            insights = []
            for insight in insights_data.get('insights', []):
                pb_insight = translation_pb2.AIInsight(
                    id=insight.get('id', ''),
                    type=insight.get('type', ''),
                    title=insight.get('title', ''),
                    description=insight.get('description', ''),
                    impact=insight.get('impact', ''),
                    timestamp=insight.get('timestamp', ''),
                    data=json.dumps(insight.get('data', {}))
                )
                insights.append(pb_insight)
            
            return translation_pb2.AIInsightsResponse(
                session_id=session_id,
                insights=insights,
                total_insights=insights_data.get('total_insights', 0),
                success=True,
                message='AI insights retrieved successfully'
            )
            
        except Exception as e:
            logger.error(f"Error getting AI insights for session {session_id}: {e}")
            return translation_pb2.AIInsightsResponse(
                session_id=session_id,
                insights=[],
                total_insights=0,
                success=False,
                message=f'Error retrieving AI insights: {str(e)}'
            )

    async def export_partial_video(self, session_id: str) -> str | None:
        """Export partial video from completed segments"""
        try:
            # Get session info
            session_info = self.active_sessions.get(session_id, {})
            if not session_info:
                return None
            
            # Get completed segments from pipeline
            pipeline = session_info.get('pipeline')
            if not pipeline:
                return None
            
            # Use pipeline's export_partial method
            partial_path = await pipeline.export_partial_video(session_id)
            return partial_path
            
        except Exception as e:
            logger.error(f"Failed to export partial video for session {session_id}: {e}")
            return None

    def get_hardware_info(self) -> Dict[str, Any]:
        """Get hardware information for ETA calculation"""
        try:
            import psutil
            import torch
            
            # Get CPU info
            cpu_count = psutil.cpu_count()
            cpu_freq = psutil.cpu_freq()
            cpu_name = f"CPU ({cpu_count} cores)"
            if cpu_freq:
                cpu_name += f" @ {cpu_freq.max:.0f}MHz"
            
            # Get GPU info
            gpu_name = "No GPU"
            vram_gb = 0
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                vram_gb = torch.cuda.get_device_properties(0).total_memory // (1024**3)
            
            # Get RAM info
            ram_gb = psutil.virtual_memory().total // (1024**3)
            
            return {
                'cpu': cpu_name,
                'gpu': gpu_name,
                'vram_gb': vram_gb,
                'ram_gb': ram_gb
            }
            
        except Exception as e:
            logger.warning(f"Failed to get hardware info: {e}")
            return {
                'cpu': 'Unknown',
                'gpu': 'Unknown',
                'vram_gb': 0,
                'ram_gb': 8
            }

    def calculate_eta(self, session_id: str, current_progress: float) -> int:
        """Calculate estimated time remaining in seconds"""
        try:
            session_info = self.active_sessions.get(session_id, {})
            if not session_info:
                return 0
            
            # Get timing info
            start_time = session_info.get('start_time')
            if not start_time:
                return 0
            
            import time
            elapsed_time = time.time() - start_time
            
            if current_progress <= 0:
                return 0
            
            # Calculate ETA based on current progress
            total_estimated_time = elapsed_time / (current_progress / 100)
            remaining_time = total_estimated_time - elapsed_time
            
            return max(0, int(remaining_time))
            
        except Exception as e:
            logger.warning(f"Failed to calculate ETA: {e}")
            return 0
